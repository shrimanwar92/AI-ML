{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a5f98ff-984d-4f81-87e8-a5125bcf4cfe",
   "metadata": {},
   "source": [
    "## Feature extraction with data augmentation\n",
    "\n",
    "#### Freezing the convolutional base in a neural network means preventing its weights from being updated during training. This is crucial because if the pre-trained representations in the convolutional base were modified, the randomly initialized Dense layers on top would propagate very large weight updates, effectively destroying the valuable learned representations. In Keras, this is achieved by setting the trainable attribute of the layer or model to False."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d51d21a1-2773-4166-b01b-f5efa08cc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "from keras import layers\n",
    "from keras.utils import image_dataset_from_directory\n",
    "import os, shutil, pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f3c7e1f-029f-428c-bcb7-af4ccfeded2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2000 files belonging to 2 classes.\n",
      "Found 1000 files belonging to 2 classes.\n",
      "Found 2000 files belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "original_dir = pathlib.Path(\"cats-dogs-images\")\n",
    "new_base_dir = pathlib.Path(\"cats_vs_dogs_subset\")\n",
    "\n",
    "train_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"train\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32\n",
    ")\n",
    "validation_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"validation\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32\n",
    ")\n",
    "test_dataset = image_dataset_from_directory(\n",
    "    new_base_dir / \"test\",\n",
    "    image_size=(180, 180),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1de53c03-99a4-4d95-902b-8dfa88ed303f",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_base = keras.applications.vgg16.VGG16(\n",
    "    weights=\"imagenet\",\n",
    "    include_top=False # meaning we won't be using the pretrained model's Dense classifier layers as it contains 1000 classifiers we won't need, we will be adding our own dense layer classifiers as we only need 2 classifier.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d9bf004-27f6-48dd-abb9-0e7a47f1e1a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is the number of trainable weights before freezing the conv base: 26\n",
      "This is the number of trainable weights after freezing the conv base: 0\n"
     ]
    }
   ],
   "source": [
    "conv_base.trainable = True\n",
    "print(\"This is the number of trainable weights \" \n",
    "\"before freezing the conv base:\", len(conv_base.trainable_weights))\n",
    "\n",
    "conv_base.trainable = False\n",
    "print(\"This is the number of trainable weights \" \n",
    "\"after freezing the conv base:\", len(conv_base.trainable_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c593ca14-f620-40f0-bb11-2f4f0d256341",
   "metadata": {},
   "source": [
    "<h5>We require 3 things:</h5>\n",
    "<ul style=\"list-style-type: disc; color: blue; font-family: Arial, sans-serif;\">\n",
    "    <li>Data augmentation stage</li>\n",
    "    <li>Frozen convolution base [conv_base] from above</li>\n",
    "    <li>A Dense classifier</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1a3aa5b-4a4f-474d-a99a-12640e44f582",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_augmentation = keras.Sequential([\n",
    "    layers.RandomFlip(\"horizontal\"),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0)\n",
    "])\n",
    "\n",
    "inputs = keras.Input(shape=(180,180,3))\n",
    "x = data_augmentation(inputs)\n",
    "x = keras.applications.vgg16.preprocess_input(x)\n",
    "x = conv_base(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(256, activation=\"relu\")(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"rmsprop\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4625034d-a968-4961-b2e4-ac59b2db49a0",
   "metadata": {},
   "source": [
    "##### When configuring a neural network in this manner, only the weights of the two added Dense layers will be updated during training. This amounts to four weight tensors in total: a primary weight matrix and a bias vector for each of the two layers. It's crucial to compile the model after setting up this configuration for the changes to take effect. If you modify the trainability of weights after initial compilation, you must recompile the model; otherwise, your adjustments will be disregarded.  This technique is expensive enough that you should only attempt it if you have access to a GPU (such as the free GPU available in Colab)—it’s intractable on CPU. If you can’t run your code on GPU, then the previous technique is the way to go."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d4edbf-18c2-41e4-80df-294e151f1324",
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "    filepath=\"feature-extraction-with-pretrained-model-data-augmentation.keras\",\n",
    "    save_best_only=True,\n",
    "    monitor=\"val_loss\")\n",
    " ]\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=5,\n",
    "    validation_data=validation_dataset,\n",
    "    callbacks=callbacks\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

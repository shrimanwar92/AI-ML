{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "vs6gnNg8HHzM",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vs6gnNg8HHzM",
        "outputId": "1caf8c50-d968-46fa-a0cd-e6a1f1ea4397"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import zipfile\n",
        "import random, shutil\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive/')\n",
        "zip_ref = zipfile.ZipFile(\"/content/drive/My Drive/cats_vs_dogs_subset.zip\", 'r')\n",
        "zip_ref.extractall(\"/tmp\")\n",
        "zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "54cb3074-5c78-4abe-aa3e-700bd0d6958b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54cb3074-5c78-4abe-aa3e-700bd0d6958b",
        "outputId": "d2bd5770-5e22-489e-a359-95f67167acd4"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 2000 files belonging to 2 classes.\n",
            "Found 1000 files belonging to 2 classes.\n",
            "Found 2000 files belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "import pathlib\n",
        "import keras\n",
        "from keras import layers\n",
        "\n",
        "original_dir = pathlib.Path(\"/tmp/cats-dogs-images\")\n",
        "new_base_dir = pathlib.Path(\"/tmp/cats_vs_dogs_subset\")\n",
        "\n",
        "from keras.utils import image_dataset_from_directory\n",
        "\n",
        "train_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"train\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32\n",
        ")\n",
        "validation_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"validation\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32\n",
        ")\n",
        "test_dataset = image_dataset_from_directory(\n",
        "    new_base_dir / \"test\",\n",
        "    image_size=(180, 180),\n",
        "    batch_size=32\n",
        ")\n",
        "\n",
        "data_augmentation = keras.Sequential([\n",
        "    layers.RandomFlip(\"horizontal\"), # Applies horizontal flipping to a random 50% of the images that go through it\n",
        "    layers.RandomRotation(0.2), # Rotates the input images by a random value in the range [–10%, +10%] | [–36 degrees, +36 degrees]\n",
        "    layers.RandomZoom(0.2) # Zooms in or out of the image by a random factor in the range [-20%, +20%]\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f220ba8e-bd59-4ffd-aba4-dbc1bb4cda9a",
      "metadata": {
        "id": "f220ba8e-bd59-4ffd-aba4-dbc1bb4cda9a"
      },
      "outputs": [],
      "source": [
        "inputs = keras.Input(shape=(180, 180, 3))\n",
        "x = data_augmentation(inputs)\n",
        "x = layers.Rescaling(1./255)(x)\n",
        "# the first layer in our model is a regular Conv2D layer. We’ll start using SeparableConv2D afterwards.\n",
        "# when we do BatchNormalization and put activation after BatchNormalization we do use_bias=False\n",
        "x = layers.Conv2D(filters=32, kernel_size=5, use_bias=False)(x)\n",
        "\n",
        "# We apply a series of convolutional blocks with increasing feature depth.\n",
        "# Each block consists of two batch-normalized depthwise separable convolution layers\n",
        "# and a max pooling layer, with a residual connection around the entire block.\n",
        "for size in [32, 64, 128, 256, 512]:\n",
        "    residual = x\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    x = layers.Activation(\"relu\")(x)\n",
        "    x = layers.SeparableConv2D(size, 3, padding=\"same\", use_bias=False)(x)\n",
        "\n",
        "    x = layers.MaxPooling2D(size, strides=2, padding=\"same\")(x)\n",
        "\n",
        "    # If we use MaxPooling, we use a strided convolution to project the residual to correct shape\n",
        "    residual = layers.Conv2D(size, 1, strides=2, padding=\"same\", use_bias=False)(residual)\n",
        "    x = layers.add([x, residual])\n",
        "\n",
        "# In the original model, we used a Flatten layer before the Dense layer. Here, we go with a GlobalAveragePooling2D layer.\n",
        "x = layers.GlobalAveragePooling2D()(x)\n",
        "x = layers.Dropout(0.5)(x) # Like in the original model, we add a dropout layer for regularization.\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model = keras.Model(inputs=inputs, outputs=outputs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34cdf3aa-0215-409a-9050-aba5f9215d3d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34cdf3aa-0215-409a-9050-aba5f9215d3d",
        "outputId": "be77ec0a-5fb3-4974-fd53-851271179235"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 1s/step - accuracy: 0.5304 - loss: 0.8805 - val_accuracy: 0.5010 - val_loss: 0.6929\n",
            "Epoch 2/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m138s\u001b[0m 1s/step - accuracy: 0.6062 - loss: 0.6588 - val_accuracy: 0.4980 - val_loss: 0.6924\n",
            "Epoch 3/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.6387 - loss: 0.6432 - val_accuracy: 0.5000 - val_loss: 0.6938\n",
            "Epoch 4/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.6785 - loss: 0.6128 - val_accuracy: 0.5400 - val_loss: 0.6904\n",
            "Epoch 5/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.6897 - loss: 0.5803 - val_accuracy: 0.5000 - val_loss: 0.6954\n",
            "Epoch 6/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.7104 - loss: 0.5527 - val_accuracy: 0.6440 - val_loss: 0.6588\n",
            "Epoch 7/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7214 - loss: 0.5463 - val_accuracy: 0.5790 - val_loss: 0.6479\n",
            "Epoch 8/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7224 - loss: 0.5371 - val_accuracy: 0.5520 - val_loss: 0.7750\n",
            "Epoch 9/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.7477 - loss: 0.5373 - val_accuracy: 0.6710 - val_loss: 0.6197\n",
            "Epoch 10/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.7478 - loss: 0.5394 - val_accuracy: 0.7010 - val_loss: 0.5612\n",
            "Epoch 11/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7605 - loss: 0.5056 - val_accuracy: 0.6620 - val_loss: 0.6775\n",
            "Epoch 12/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7540 - loss: 0.5013 - val_accuracy: 0.7080 - val_loss: 0.7060\n",
            "Epoch 13/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7642 - loss: 0.4904 - val_accuracy: 0.5870 - val_loss: 0.8482\n",
            "Epoch 14/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7684 - loss: 0.4816 - val_accuracy: 0.6060 - val_loss: 0.6837\n",
            "Epoch 15/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.7775 - loss: 0.4693 - val_accuracy: 0.6560 - val_loss: 0.6033\n",
            "Epoch 16/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.7683 - loss: 0.4760 - val_accuracy: 0.7130 - val_loss: 0.6404\n",
            "Epoch 17/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7930 - loss: 0.4445 - val_accuracy: 0.6200 - val_loss: 1.2608\n",
            "Epoch 18/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7858 - loss: 0.4481 - val_accuracy: 0.7270 - val_loss: 0.5596\n",
            "Epoch 19/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8021 - loss: 0.4510 - val_accuracy: 0.6340 - val_loss: 0.8383\n",
            "Epoch 20/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7920 - loss: 0.4546 - val_accuracy: 0.7220 - val_loss: 0.5514\n",
            "Epoch 21/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7814 - loss: 0.4406 - val_accuracy: 0.7110 - val_loss: 0.6027\n",
            "Epoch 22/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.7930 - loss: 0.4559 - val_accuracy: 0.6050 - val_loss: 1.0529\n",
            "Epoch 23/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8084 - loss: 0.4210 - val_accuracy: 0.5910 - val_loss: 1.2020\n",
            "Epoch 24/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.7926 - loss: 0.4518 - val_accuracy: 0.6550 - val_loss: 0.8905\n",
            "Epoch 25/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 1s/step - accuracy: 0.8324 - loss: 0.3991 - val_accuracy: 0.5940 - val_loss: 1.1437\n",
            "Epoch 26/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8237 - loss: 0.4004 - val_accuracy: 0.7620 - val_loss: 0.5829\n",
            "Epoch 27/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8030 - loss: 0.4066 - val_accuracy: 0.6820 - val_loss: 0.8264\n",
            "Epoch 28/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8124 - loss: 0.4021 - val_accuracy: 0.7700 - val_loss: 0.5653\n",
            "Epoch 29/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8309 - loss: 0.3726 - val_accuracy: 0.7730 - val_loss: 0.4928\n",
            "Epoch 30/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8330 - loss: 0.3565 - val_accuracy: 0.7010 - val_loss: 0.6646\n",
            "Epoch 31/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8265 - loss: 0.3713 - val_accuracy: 0.5590 - val_loss: 1.4555\n",
            "Epoch 32/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8278 - loss: 0.3656 - val_accuracy: 0.7580 - val_loss: 0.6155\n",
            "Epoch 33/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 1s/step - accuracy: 0.8360 - loss: 0.3452 - val_accuracy: 0.7850 - val_loss: 0.4838\n",
            "Epoch 34/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 1s/step - accuracy: 0.8342 - loss: 0.3549 - val_accuracy: 0.6940 - val_loss: 0.8855\n",
            "Epoch 35/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8257 - loss: 0.3701 - val_accuracy: 0.7440 - val_loss: 0.6067\n",
            "Epoch 36/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8461 - loss: 0.3270 - val_accuracy: 0.7290 - val_loss: 0.5464\n",
            "Epoch 37/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m141s\u001b[0m 1s/step - accuracy: 0.8405 - loss: 0.3540 - val_accuracy: 0.8120 - val_loss: 0.4368\n",
            "Epoch 38/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m142s\u001b[0m 1s/step - accuracy: 0.8489 - loss: 0.3451 - val_accuracy: 0.7440 - val_loss: 0.6457\n",
            "Epoch 39/50\n",
            "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1s/step - accuracy: 0.8662 - loss: 0.3298"
          ]
        }
      ],
      "source": [
        "model.compile(\n",
        "    optimizer=\"rmsprop\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=[\"accuracy\"]\n",
        ")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"mini-xception-model.keras\",\n",
        "    save_best_only=True,\n",
        "    monitor=\"val_loss\")\n",
        "]\n",
        "\n",
        "history = model.fit(\n",
        "    train_dataset,\n",
        "    epochs=50,\n",
        "    validation_data=validation_dataset,\n",
        "    callbacks=callbacks\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aad163b3-1fbe-4004-bbc8-a7ff482fad5e",
      "metadata": {
        "id": "aad163b3-1fbe-4004-bbc8-a7ff482fad5e"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.5"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
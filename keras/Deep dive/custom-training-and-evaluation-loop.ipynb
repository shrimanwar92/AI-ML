{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72fbb7d2-ba78-48c8-9a76-29a9a6399388",
   "metadata": {},
   "source": [
    "## Writing your own training and evaluation loops\n",
    "#### The fit() workflow strikes a nice balance between ease of use and flexibility. The built-in fit() workflow is solely focused on supervised learning: a setup where there are known targets (also called labels or annotations) associated with your input data, and where you compute your loss [as a function] between these targets and the model’s predictions.\n",
    "#### There are other setups where no explicit targets are present, such as generative learning, self-supervised learning (where targets are obtained from the inputs), and reinforcement learning (where learning is driven by occasional “rewards,” much like training a dog).\n",
    "#### Whenever you find yourself in a situation where the built-in fit() is not enough, you will need to write your own custom training logic.\n",
    "####  The pseudo-code typical training loop look like this:\n",
    "\n",
    "#####  1) Run the forward pass (compute the model’s output) inside a gradient tape to obtain a loss value for the current batch of data\n",
    "##### 2) Retrieve the gradients of the loss with regard to the model’s weights.\n",
    "##### 3) Update the model’s weights so as to lower the loss value on the current batch of data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f51694-8cec-41e5-b74b-1eca4cde3dbf",
   "metadata": {},
   "source": [
    "### Training versus inference\n",
    "       \n",
    "\n",
    "#### Training vs. Inference Behavior: \n",
    "    Some Keras layers, like Dropout and BatchNormalization, act differently during training and inference (when making predictions). They have a training argument in their call() method. Calling dropout(inputs,training=True) will drop some activation entries, while calling dropout(inputs,training=False) does nothing. Crucially, remember to set training=True when calling your model (Functional or Sequential) during the forward pass in your training loop. This ensures these layers behave correctly during training.\n",
    "#### Trainable vs. Non-Trainable Weights: Keras models and layers have two types of weights:\n",
    "    1) Trainable weights: These are the standard weights that are updated by backpropagation (e.g., kernel and bias in a Dense layer).\n",
    "    2) Non-trainable weights: These are updated during the forward pass by the layer itself. A built-in example is the BatchNormalization layer, which uses non-trainable weights to track the mean and standard deviation of the input data.\n",
    "#### Gradient Calculation: \n",
    "    When calculating gradients, use \n",
    "    tape.gradient(loss, model.trainable_weights) instead of \n",
    "    tape.gradient(loss, model.weights). \n",
    "    This ensures you only compute gradients for the weights that should be updated during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d5c8eab0-2e17-4108-85a9-cc9b53d03fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.datasets import mnist\n",
    "from keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "11fa7bc7-c757-4357-926c-afc64b2b4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mnist_model():\n",
    "    inputs = keras.Input(shape=(28 * 28,))\n",
    "    features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "    features = layers.Dropout(0.5)(features)\n",
    "    outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "    model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9d6cd80e-8722-4adf-b32b-d046ed316dc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "(images, labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(images[0])\n",
    "plt.colorbar()\n",
    "plt.grid(False)\n",
    "plt.show()\n",
    "\n",
    "images = images.reshape((60000, 28*28)).astype(\"float32\") / 255\n",
    "test_images = test_images.reshape((10000, 28*28)).astype(\"float32\") / 255\n",
    "\n",
    "train_images, val_images = images[10000:], images[:10000]\n",
    "train_labels, val_labels = labels[10000:], labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d1204766-b95f-4342-a85e-87a74633da80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras\n",
    "def training_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = model(inputs, Training=True)\n",
    "        loss = loss_function(targets, predictions)\n",
    "        gradients = tape.gradients(loss, model.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(model.trainable_weights, gradients))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87f32974-3180-4075-8979-a02cdaf1d4f7",
   "metadata": {},
   "source": [
    "### Low-level usage of metrics\n",
    "#### In a low-level training loop, you will probably want to leverage Keras metrics. call `update_state(y_true, y_pred)` for each batch of targets and predictions, and then use `result()` to query the current metric value. Remember to use `metric.reset_state()` when you want to reset the current results (at the start of a training epoch or at the start of evaluation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4f4415e1-c6e2-470e-8900-b3cd1fa1b428",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "result: 1.00\n"
     ]
    }
   ],
   "source": [
    "metric = keras.metrics.SparseCategoricalAccuracy()\n",
    "targets = [0, 1, 2]\n",
    "predictions = [[1, 0, 0], [0, 1, 0], [0, 0, 1]]\n",
    "metric.update_state(targets, predictions)\n",
    "current_result = metric.result()\n",
    "print(f\"result: {current_result:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e00e6f3-d86c-4c4d-bebd-41587d03ac6b",
   "metadata": {},
   "source": [
    "### A complete training and evaluation loop\n",
    "#### Writing a step-by-step training loop: the training step function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5a54d302-a5b9-411d-8337-4280b5a763b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.enable_eager_execution()\n",
    "print(tf.executing_eagerly())\n",
    "\n",
    "model = get_mnist_model()\n",
    "\n",
    "loss_fn = keras.losses.SparseCategoricalCrossentropy() # prepare loss function\n",
    "optimizer = keras.optimizers.RMSprop()                 # prepare the optimizer\n",
    "metrics = [keras.metrics.SparseCategoricalAccuracy()]  # prepare the list of metrics to monitor\n",
    "loss_tracking_metric = keras.metrics.Mean()            # prepare a Mean metric tracker to keep track of the loss average\n",
    "\n",
    "def train_step(inputs, targets):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # run the forward pass. Note that we pass training=True\n",
    "        predictions = model(inputs, training=True)\n",
    "        loss = loss_fn(targets, predictions)\n",
    "    \n",
    "    # run the backward pass Note that we use model.trainable_weights.\n",
    "    gradients = tape.gradient(loss, model.trainable_weights) # find the direction in the curve that minimizes the loss\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_weights)) # move in the opposite direction of the gradients W = W - LR*gradient \n",
    "\n",
    "    # keep track of metrics\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[metric.name] = metric.result()\n",
    "\n",
    "    # keep track of loss average\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f8901d-428e-4888-bc94-a6b60f779cd5",
   "metadata": {},
   "source": [
    "#### Writing a step-by-step training loop: resetting the metrics\n",
    "##### We will need to reset the state of our metrics at the start of each epoch and before running evaluation. Here’s a utility function to do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6689c77-91f2-4d66-93d1-205289a5dcf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reset_metrics():\n",
    "    for metric in metrics:\n",
    "        metric.reset_state()\n",
    "    loss_tracking_metric.reset_state()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d19c4fe-2a25-49ed-982c-4fa69384eb71",
   "metadata": {},
   "source": [
    "#### Writing a step-by-step training loop: the loop itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6a825282-627a-4c82-aea1-5fa6847cc421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results at the end of epoch 0\n",
      "...sparse_categorical_accuracy: 0.9136\n",
      "...loss: 0.2924\n",
      "Results at the end of epoch 1\n",
      "...sparse_categorical_accuracy: 0.9526\n",
      "...loss: 0.1604\n",
      "Results at the end of epoch 2\n",
      "...sparse_categorical_accuracy: 0.9648\n",
      "...loss: 0.1298\n"
     ]
    }
   ],
   "source": [
    "# Using tf.data.Dataset object to turn our NumPy data into an iterator that iterates over the data in batches of size 32\n",
    "\n",
    "training_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels))\n",
    "training_dataset = training_dataset.batch(32)\n",
    "epochs = 3\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    reset_metrics()\n",
    "    for inputs_batch, targets_batch in training_dataset:\n",
    "        logs = train_step(inputs_batch, targets_batch)\n",
    "    print(f\"Results at the end of epoch {epoch}\")\n",
    "    for key, value in logs.items():\n",
    "        print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8338d05b-74e8-4185-a831-ca7440f8b825",
   "metadata": {},
   "source": [
    "##### Evaluation loop: a simple for loop that repeatedly calls a test_step() function, which processes a single batch of data. The test_step() function is just a subset of the logic of train_step(). It omits the code that deals with updating the weights of the model—that is to say, everything involving the GradientTape and the optimizer.\n",
    "##### while you are debugging your code, prefer running it eagerly, without any @tf.function decorator. It’s easier to track bugs this way. Once your code is working and you want to make it fast, add a @tf.function decorator to your training step and your evaluation step—or any other performance-critical function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "28debf30-0071-4798-a26e-0dd742d0f4f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results:\n",
      "...val_sparse_categorical_accuracy: 0.9692\n",
      "...val_loss: 0.1198\n"
     ]
    }
   ],
   "source": [
    "@tf.function()\n",
    "def test_step(inputs, targets):\n",
    "    predictions = model(inputs, training=False)\n",
    "    loss = loss_fn(targets, predictions)\n",
    "\n",
    "    logs = {}\n",
    "    for metric in metrics:\n",
    "        metric.update_state(targets, predictions)\n",
    "        logs[\"val_\" + metric.name] = metric.result()\n",
    "\n",
    "    loss_tracking_metric.update_state(loss)\n",
    "    logs[\"val_loss\"] = loss_tracking_metric.result()\n",
    "    return logs\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_labels))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "\n",
    "reset_metrics()\n",
    "\n",
    "for inputs_batch, targets_batch in val_dataset:\n",
    "    logs = test_step(inputs_batch, targets_batch)\n",
    "print(\"Evaluation results:\")\n",
    "for key, value in logs.items(): \n",
    "    print(f\"...{key}: {value:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0337e16e-17a8-4855-bf4d-152f897c1bb7",
   "metadata": {},
   "source": [
    "### Leveraging fit() with a custom training loop\n",
    "#### Implementing a custom training step to use with fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "d91e7e89-ab95-4594-addf-cb5585ea8db4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "loss_fn = keras.losses.SparseCategoricalCrossentropy()\n",
    "#This metric object will be used to track the average of per-batch losses during training and evaluation.\n",
    "loss_tracker = keras.metrics.Mean(name=\"loss\")\n",
    "\n",
    "class CustomModel(keras.Model):\n",
    "    # We override the train_step method.\n",
    "    \n",
    "    def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            # We use self(inputs, training=True) instead of model(inputs, training=True), \n",
    "            # since our model is the class itself.\n",
    "\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = loss_fn(targets, predictions)\n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
    "\n",
    "        #  We update the loss tracker metric that tracks the average of the loss.\n",
    "        loss_tracker.update_state(loss)\n",
    "        \n",
    "        # We return the average loss so far by querying the loss tracker metric\n",
    "        return {\"loss\": loss_tracker.result()}\n",
    "\n",
    "    # Any metric you would like to reset across epochs should be listed here.\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [loss_tracker]\n",
    "       \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dd72ac-febb-486b-bc33-99477d38a088",
   "metadata": {},
   "source": [
    "#####  We can now instantiate our custom model, compile it (we only pass the optimizer, since the loss is already defined outside of the model), and train it using fit() as usual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "a023ef94-4759-4682-9c03-9e074f304840",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.4519\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1588\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - loss: 0.1306\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x111c35cbd40>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop())\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92399916-9e9e-4cef-ad0d-1b8ac39f1e0d",
   "metadata": {},
   "source": [
    "### Notes\n",
    "    1) This pattern does not prevent you from building models with the Functional API. You can do this whether you’re building Sequential models, Functional API models, or subclassed models.\n",
    "    2) You don’t need to use a @tf.function decorator when you override train_step—the framework does it for you.\n",
    "    3) After you’ve called compile(), you get access to the following:\n",
    "        a) self.compiled_loss—The loss function you passed to compile()\n",
    "        b) self.compiled_metrics—A wrapper for the list of metrics you passed, which allows you to call           self.compiled_metrics.update_state() to update all of your metrics at once.\n",
    "        c) self.metrics—The actual list of metrics you passed to compile(). Note that it also includes a metric that tracks the loss, similar to what we did manually with our loss_tracking_metric earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b1b6a035-a7df-4b0a-96cb-501e2cdb054a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(keras.Model):\n",
    "     def train_step(self, data):\n",
    "        inputs, targets = data\n",
    "        with tf.GradientTape() as tape:\n",
    "            predictions = self(inputs, training=True)\n",
    "            loss = self.compiled_loss(targets, predictions)   \n",
    "        gradients = tape.gradient(loss, self.trainable_weights)\n",
    "        optimizer.apply_gradients(zip(gradients, model.trainable_weights))\n",
    "        self.compiled_metrics.update_state(targets, predictions)  \n",
    "        return {m.name: m.result() for m in self.metrics}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "106ad96e-4b9f-4994-a565-6e278725ec55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\\\\?\\C:\\Users\\shrim\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\Lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:640: UserWarning: `model.compiled_metrics()` is deprecated. Instead, use e.g.:\n",
      "```\n",
      "for metric in self.metrics:\n",
      "    metric.update_state(y, y_pred)\n",
      "```\n",
      "\n",
      "  return self._compiled_metrics_update_state(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - sparse_categorical_accuracy: 0.8639 - loss: 0.1000\n",
      "Epoch 2/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - sparse_categorical_accuracy: 0.9522 - loss: 0.1000\n",
      "Epoch 3/3\n",
      "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - sparse_categorical_accuracy: 0.9634 - loss: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x111bdc114f0>"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = keras.Input(shape=(28 * 28,))\n",
    "features = layers.Dense(512, activation=\"relu\")(inputs)\n",
    "features = layers.Dropout(0.5)(features)\n",
    "outputs = layers.Dense(10, activation=\"softmax\")(features)\n",
    "model = CustomModel(inputs, outputs)\n",
    "model.compile(optimizer=keras.optimizers.RMSprop(),\n",
    "      loss=keras.losses.SparseCategoricalCrossentropy(),\n",
    "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "model.fit(train_images, train_labels, epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3c18ab-6789-4dc8-8d51-370625c14d91",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
